\chapter{Callbacks} \label{chap:callbacks}

\begin{synopsis}
\end{synopsis}
\minitoc
\vspace{\fill}
\newpage

\section{Data callbacks}
\subsection{The \texttt{adj_vector} and \texttt{adj_matrix} types}
\defapiss{adj_vector}
\defapiss{adj_matrix}
\subsection{Registering data callbacks}
\defapiss{adj_register_data_callback}
\subsection{Vector callbacks}
\defapiss{ADJ_VEC_DUPLICATE_CB}
\begin{framed}
\begin{minipage}{\columnwidth}
\begin{ccode}
  void vec_duplicate(adj_vector x, adj_vector *newx);
\end{ccode}
\begin{fortrancode}
  subroutine vec_duplicate(x, newx) bind(c)
    type(adj_vector), intent(in), value :: x
    type(adj_vector), intent(out) :: newx
  end subroutine vec_duplicate
\end{fortrancode}
\end{minipage}
\end{framed}
This data callback is the fundamental allocation callback. \libadjoint
often needs to create new vectors for various tasks; \texttt{x} is an
input model \refapi{adj_vector} to be duplicated, while \texttt{newx} is the new vector
to be allocated. Note that this callback \textbf{must initialise the contents of \texttt{newx} to zero}.

When necessary: always.
\defapiss{ADJ_VEC_AXPY_CB}
\begin{framed}
\begin{minipage}{\columnwidth}
\begin{ccode}
  void vec_axpy(adj_vector *y, adj_scalar alpha, adj_vector x);
\end{ccode}
\begin{fortrancode}
  subroutine vec_axpy(y, alpha, x) bind(c)
    type(adj_vector), intent(inout) :: y
    adj_scalar_f, intent(in), value :: alpha
    type(adj_vector), intent(in), value :: x
  end subroutine vec_axpy
\end{fortrancode}
\end{minipage}
\end{framed}
This data callback adds one vector to another, i.e.\ executes
\begin{equation*}
y \leftarrow y + \alpha x.
\end{equation*}

When necessary: always.
\defapiss{ADJ_VEC_DESTROY_CB}
\begin{framed}
\begin{minipage}{\columnwidth}
\begin{ccode}
  void vec_destroy(adj_vector *x);
\end{ccode}
\begin{fortrancode}
  subroutine vec_destroy(x) bind(c)
    type(adj_vector), intent(inout) :: x
  end subroutine adj_vec_destroy
\end{fortrancode}
\end{minipage}
\end{framed}
This data callback is called when \libadjoint is finished
with a vector; it is used to deallocate its memory and free
its resources.

When necessary: always.
\defapiss{ADJ_VEC_SET_VALUES_CB}
\begin{framed}
\begin{minipage}{\columnwidth}
\begin{ccode}
  void vec_set_values(adj_vector *x, adj_scalar* scalars);
\end{ccode}
\begin{fortrancode}
  subroutine vec_set_values(vec, scalars) bind(c)
    type(adj_vector), intent(inout) :: vec
    adj_scalar_f, dimension(*), intent(in) :: scalars
  end subroutine vec_set_values
\end{fortrancode}
\end{minipage}
\end{framed}
This data callback sets a given \refapi{adj_vector} from an array
of \texttt{adj_scalar}s. The length of the array is the output of
the \refapi{ADJ_VEC_GET_SIZE_CB} data callback.

When necessary: this data callback is necessary when the derivative test flag
is activated on an \refapi{adj_nonlinear_block} with \refapi{adj_nonlinear_block_set_test_derivative}.
\defapiss{ADJ_VEC_GET_SIZE_CB}
\begin{framed}
\begin{minipage}{\columnwidth}
\begin{ccode}
  void vec_get_norm(adj_vector x, int* sz);
\end{ccode}
\begin{fortrancode}
  subroutine vec_get_size(vec, sz) bind(c)
    type(adj_vector), intent(in), value :: vec
    integer(kind=c_int), intent(out) :: sz
  end subroutine vec_get_size
\end{fortrancode}
\end{minipage}
\end{framed}
This data callback returns the number of degrees of freedom in a given \refapi{adj_vector}. The
vector space of all such \refapi{adj_vector}s should be isomorphic to $\mathbb{R}^n$ for some $n$;
this callback returns $n$.

When necessary: this data callback is necessary when the derivative test flag
is activated on an \refapi{adj_nonlinear_block} with \refapi{adj_nonlinear_block_set_test_derivative}.
\defapiss{ADJ_VEC_GET_NORM_CB}
\begin{framed}
\begin{minipage}{\columnwidth}
\begin{ccode}
  void vec_get_norm(adj_vector x, adj_scalar* norm);
\end{ccode}
\begin{fortrancode}
  subroutine vec_norm(x, norm) bind(c)
    type(adj_vector), intent(in), value :: x
    adj_scalar_f, intent(out) :: norm
  end subroutine vec_norm
\end{fortrancode}
\end{minipage}
\end{framed}
This data callback computes the norm of a given vector. It does not matter
which norm is chosen, so long as it satisfies the usual axioms for a norm.

When necessary: this data callback is necessary when the derivative test flag
is activated on an \refapi{adj_nonlinear_block} with \refapi{adj_nonlinear_block_set_test_derivative}.

\defapiss{ADJ_VEC_SET_RANDOM_CB}
\begin{framed}
\begin{minipage}{\columnwidth}
\begin{ccode}
  void vec_set_random(adj_vector *x);
\end{ccode}
\begin{fortrancode}
  subroutine vec_set_random(x) bind(c)
    type(adj_vector), intent(inout) :: x
  end subroutine vec_set_random
\end{fortrancode}
\end{minipage}
\end{framed}
This data callback sets the entries of a given vector \texttt{x} to pseudo-random values.

When necessary: this data callback is necessary when the hermitian test flag is
activated on an \refapi{adj_block} with \refapi{adj_block_set_test_hermitian},
or on an \refapi{adj_nonlinear_block} with \\\refapi{adj_nonlinear_block_set_test_hermitian}.

\defapiss{ADJ_VEC_DOT_PRODUCT_CB}
\begin{framed}
\begin{minipage}{\columnwidth}
\begin{ccode}
  void vec_dot_product(adj_vector x, adj_vector y, adj_scalar* val);
\end{ccode}
\begin{fortrancode}
  subroutine vec_dot_product(x, y, val) bind(c)
    type(adj_vector), intent(in), value :: x, y
    adj_scalar_f, intent(out) :: val
  end subroutine vec_dot_product
\end{fortrancode}
\end{minipage}
\end{framed}
This data callback computes the dot product (inner product) of two \refapi{adj_vector}s.

When necessary: this data callback is necessary when the hermitian test flag is
activated on an \refapi{adj_block} with \refapi{adj_block_set_test_hermitian},
or on an \refapi{adj_nonlinear_block} with \\\refapi{adj_nonlinear_block_set_test_hermitian}.
\subsection{Matrix callbacks}
\defapiss{ADJ_MAT_DUPLICATE_CB}
\defapiss{ADJ_MAT_AXPY_CB}
\defapiss{ADJ_MAT_DESTROY_CB}
\subsection{Supplied data callbacks}
\defapiss{adj_set_petsc_data_callbacks}

\section{Operator callbacks}
\defapis{adj_register_operator_callback}

\section{Source-term callbacks}
\defapis{adj_register_forward_source_callback}
\defapis{adj_register_functional_derivative_callback}

\section{Functional evaluation callbacks}
\defapis{adj_register_functional_callback}
